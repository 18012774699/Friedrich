## **分类算法**

### **对性能的评估**

### **1、使用交叉验证测量准确性**

### **2、混淆矩阵**

 对分类器来说，一个好得多的性能评估指标是混淆矩阵。 

![img](https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg)

### **3、准确率、召回率、 F1 值** 

```
准确率：TP/(TP+FP)
召回率：TP/(TP+FN)
F1 值：TP/(TP+(FN+FP)/2)
```

![img](https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg)

### **4、准确率/召回率曲线和ROC 曲线**

```
cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
confusion_matrix(y_train_5, y_train_pred)
precision_score(y_train_5, y_train_pred)
recall_score(y_train_5, y_train_pred)
f1_score(y_train_5, y_train_pred)
precision_recall_curve(y_train_5, y_scores)
roc_curve(y_train_5, y_scores)
roc_auc_score(y_train_5, y_scores)
```

### **5、多类分类**

 二分类器只能区分两个类，而多类分类器（也被叫做多项式分类器）可以区分多于两个类。 

 一些算法（比如随机森林分类器或者朴素贝叶斯分类器）可以直接处理多类分类问题。其他一些算法（比如 SVM 分类器或者线性分类器）则是严格的二分类器。

有许多策略可以让你用二分类器去执行多类分类。 

（OvA）：创建一个可以将图片分成 10 类（从 0 到 9）的系统的一个方法是：训练10个二分类器，每一个对应一个数字（探测器 0，探测器 1，探测器 2，以此类推）。 

（OvO）： 另一个策略是对每一对数字都训练一个二分类器：一个分类器用来处理数字 0 和数字 1，一个用来处理数字 0 和数字 2，一个用来处理数字 1 和 2，以此类推。 

```
>>> from sklearn.multiclass import OneVsOneClassifier
>>> ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))
>>> ovo_clf.fit(X_train, y_train)
>>> ovo_clf.predict([some_digit])
array([ 5.])
>>> len(ovo_clf.estimators_)
45
```

### **误差分析**

### **多标签分类**

 KNeighborsClassifier 

### **多输出分类**

 KNeighborsClassifier 

降噪

## **训练模型**

### **计算复杂度**

正态方程需要计算矩阵XT的逆。X是一个n x n的矩阵（n是特征的个数）。这样一个矩阵求逆的运算复杂度大约在O(n2.4)到O(n3)之间，具体值取决于计算方式。换句话说，如果你将你的特征个数翻倍的话，其计算时间大概会变为原来的 22.4 = 5.3 到 23 = 8倍。

有利的一面是，这个方程在训练集上对于每一个实例来说是线性的，其复杂度为O(m)，因此只要有能放得下它的内存空间，它就可以对大规模数据进行训练。同时，一旦你得到了线性回归模型（通过解正态方程或者其他的算法），进行预测是非常快的。因为模型中计算复杂度对于要进行预测的实例数量和特征个数都是线性的。 换句话说，当实例个数变为原来的两倍多的时候（或特征个数变为原来的两倍多），预测时间也仅仅是原来的两倍多。

接下来，我们将介绍另一种方法去训练模型。这种方法适合在特征个数非常多，训练实例非常多，内存无法满足要求的时候使用。

### **正态方程求解**

![img](https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg)

```
LinearRegression类
```

### **批量梯度下降**

 计算每一步的梯度时都需要使用整个训练集 。

### **随机梯度下降**

 在每一步的梯度计算上只随机选取训练集中的一个样本。 

### **小批量梯度下降**

### **多项式回归**

### **学习曲线**

![img](https://pic2.zhimg.com/v2-3c40829a650f96ab57be6975d78f8601_b.jpg)

这幅图值得我们深究。首先，我们观察在训练集上的效果：当训练集只有一两个样本的时候，模型能够非常好的拟合它们，这也是为什么曲线是从零开始的原因。但是当加入了一些新的样本的时候，训练集上的拟合程度变得难以接受，出现这种情况有两个原因，一是因为数据中含有噪声，另一个是数据根本不是线性的。因此随着数据规模的增大，误差也会一直增大，直到达到高原地带并趋于稳定，在之后，继续加入新的样本，模型的平均误差不会变得更好或者更差。我们继续来看模型在验证集上的表现，当以非常少的样本去训练时，模型不能恰当的泛化，也就是为什么验证误差一开始是非常大的。当训练样本变多的到时候，模型学习的东西变多，验证误差开始缓慢的下降。但是一条直线不可能很好的拟合这些数据，因此最后误差会到达在一个高原地带并趋于稳定，最后和训练集的曲线非常接近。

```
提示
如果你的模型在训练集上是欠拟合的，添加更多的样本是没用的。你需要使用一个更复杂的模型或者找到更好的特征。
改善模型过拟合的一种方法是提供更多的训练数据，直到训练误差和验证误差相等。
```

### **偏差和方差的权衡**

```
在统计和机器学习领域有个重要的理论：一个模型的泛化误差由三个不同误差的和决定：

偏差：泛化误差的这部分误差是由于错误的假设决定的。例如实际是一个二次模型，你却假设了一个线性模型。一个高偏差的模型最容易出现欠拟合。
方差：这部分误差是由于模型对训练数据的微小变化较为敏感，一个多自由度的模型更容易有高的方差（例如一个高阶多项式模型），因此会导致模型过拟合。
不可约误差：这部分误差是由于数据本身的噪声决定的。降低这部分误差的唯一方法就是进行数据清洗（例如：修复数据源，修复坏的传感器，识别和剔除异常值）。
```



### 线性模型的正则化

注意到这个正则项只有在训练过程中才会被加到损失函数。当得到完成训练的模型后，我们应该使用没有正则化的测量方法去评价模型的表现。

```
笔记
一般情况下，训练过程使用的损失函数和测试过程使用的评价函数是不一样的。除了正则化，还有一个不同：训练时的损失函数应该在优化过程中易于求导，而在测试过程中，评价函数更应该接近最后的客观表现。一个好的例子：在分类训练中我们使用对数损失（马上我们会讨论它）作为损失函数，但是我们却使用精确率/召回率来作为它的评价函数。
提示
在使用岭回归前，对数据进行放缩（可以使用StandardScaler）是非常重要的，算法对于输入特征的数值尺度（scale）非常敏感。大多数的正则化模型都是这样的。
```



### 如何选择

那么我们该如何选择线性回归，岭回归，Lasso 回归，弹性网络呢？

一般来说有一点正则项的表现更好，因此通常你应该避免使用简单的线性回归。岭回归是一个很好的首选项，但是如果你的特征仅有少数是真正有用的，你应该选择 Lasso 和弹性网络。就像我们讨论的那样，它两能够将无用特征的权重降为零。一般来说，弹性网络的表现要比 Lasso 好，因为当特征数量比样本的数量大的时候，或者特征之间有很强的相关性时，Lasso 可能会表现的不规律。



### 早期停止法（Early Stopping）


