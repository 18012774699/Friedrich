### **一些问题**

```
归一化的必要性：各个维度同时收敛
梯度下降类型：
跳过的问题：softmax、SVM原理、核PCA
```

### **机器学习分类：**

- 监督或非监督
- 批量或线上
- 基于实例或基于模型
- 等等

### **下面是一些重要的监督学习算法（本书都有介绍）：**

K近邻算法

线性回归

逻辑回归

支持向量机（SVM）

决策树和随机森林

神经网络

### **下面是一些最重要的非监督学习算法（我们会在第8章介绍降维）：**

- **聚类**
-  k-均值
-  层次聚类分析（Hierarchical Cluster Analysis，HCA）
-  期望最大值

- **可视化和降维**
-  主成分分析（Principal Component Analysis，PCA）
-  核主成分分析
-  局部线性嵌入（Locally-Linear Embedding，LLE）
-  t-分布邻域嵌入算法（t-distributed Stochastic Neighbor Embedding，t-SNE）

- **关联性规则学习**
-  Apriori算法
-  Eclat算法

### **验证集合和交叉验证：**

- 因此，评估一个模型很简单：只要使用测试集。现在假设你在两个模型之间犹豫不决（比如一个线性模型和一个多项式模型）：如何做决定呢？一种方法是两个都训练，然后比较在测试集上的效果。
- 现在假设线性模型的效果更好，但是你想做一些正规化以避免过拟合。问题是：如何选择正规化超参数的值？一种选项是用100个不同的超参数训练100个不同的模型。假设你发现最佳的超参数的推广错误率最低，比如只有5%。然后就选用这个模型作为生产环境，但是实际中性能不佳，误差率达到了15%。发生了什么呢？
- 答案在于，你在测试集上多次测量了推广误差率，调整了模型和超参数，以使模型最适合这个集合。这意味着模型对新数据的性能不会高。
- 这个问题通常的解决方案是，再保留一个集合，称作验证集合。用测试集和多个超参数训练多个模型，选择在验证集上有最佳性能的模型和超参数。当你对模型满意时，用测试集再做最后一次测试，以得到推广误差率的预估。
- 为了避免“浪费”过多训练数据在验证集上，通常的办法是使用交叉验证：训练集分成互补的子集，每个模型用不同的子集训练，再用剩下的子集验证。一旦确定模型类型和超参数，最终的模型使用这些超参数和全部的训练集进行训练，用测试集得到推广误差率。

### **没有免费午餐公理(NFL)：**

```
没有免费午餐公理

模型是观察的简化版本。简化意味着舍弃无法进行推广的表面细节。但是，要确定舍弃什么数据、保留什么数据，必须要做假设。例如，线性模型的假设是数据基本上是线性的，实例和模型直线间的距离只是噪音，可以放心忽略。

在一篇1996年的著名论文（goo.gl/3zaHIZ）中，David Wolpert证明，如果完全不对数据做假设，就没有理由选择一个模型而不选另一个。这称作没有免费午餐（NFL）公理。对于一些数据集，最佳模型是线性模型，而对其它数据集是神经网络。没有一个模型可以保证效果更好（如这个公理的名字所示）。确信的唯一方法就是测试所有的模型。因为这是不可能的，实际中就必须要做一些对数据合理的假设，只评估几个合理的模型。例如，对于简单任务，你可能是用不同程度的正规化评估线性模型，对于复杂问题，你可能要评估几个神经网络模型。
```

### **使用真实数据**

学习机器学习时，最好使用真实数据，而不是人工数据集。幸运的是，有上千个开源数据集可以进行选择，涵盖多个领域。以下是一些可以查找数据的资源：

- 流行的开源数据仓库： [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/) [Kaggle datasets](https://www.kaggle.com/datasets) [Amazon’s AWS datasets](http://aws.amazon.com/fr/datasets/)
- 准入口（提供开源数据列表） http://dataportals.org/ http://opendatamonitor.eu/ http://quandl.com/
- 其它列出流行开源数据仓库的网页： [Wikipedia’s list of Machine Learning datasets](https://goo.gl/SJHN2k) [Quora.com question](http://goo.gl/zDR78y) [Datasets subreddit](https://www.reddit.com/r/datasets)

