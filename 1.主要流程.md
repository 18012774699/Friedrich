### **划定问题**

- 监督或非监督，还是强化学习？
- 这是个分类任务、回归任务，还是其它的？
- 要使用批量学习还是线上学习？

```
管道

一系列的数据处理组件被称为数据管道。管道在机器学习系统中很常见，因为有许多数据要处理和转换。

组件通常是异步运行的。每个组件吸纳进大量数据，进行处理，然后将数据传输到另一个数据容器中，而后管道中的另一个组件收入这个数据，然后输出，这个过程依次进行下去。每个组件都是独立的：组件间的接口只是数据容器。这样可以让系统更便于理解（记住数据流的图），不同的项目组可以关注于不同的组件。进而，如果一个组件失效了，下游的组件使用失效组件最后生产的数据，通常可以正常运行（一段时间）。这样就使整个架构相当健壮。

另一方面，如果没有监控，失效的组件会在不被注意的情况下运行一段时间。数据会受到污染，整个系统的性能就会下降。
```

### **选择性能指标**

- **RMSE**

回归问题的典型指标是均方根误差（RMSE）
$$
RMSE(X,h)=\sqrt {\frac{1}{m}\sum^{m}_{i=1}(h(x^{(i)})-y^{(i)})^2}
$$
[等式2-1]    均方根误差（RMSE）

- **MAE**

 绝对平均误差（Mean Absolute Error，也称作平均绝对偏差 )
$$
MAE(X,h)=\frac{1}{m}\sum^{m}_{i=1}|h(x^{(i)})-y^{(i)}|
$$
[等式2-2]    绝对平均误差

- **范数**

 RMSE和MAE都是测量预测值和目标值两个矢量距离的方法。有多种测量距离的方法，或范数： 


```
1. 计算对应欧几里得范数的平方和的根（RMSE）：这个距离介绍过。它也称作ℓ2范数，标记为// · //2（或只是// · //）。
2. 计算对应于ℓ1（标记为// · //1）范数的绝对值之和（MAE）。有时，也称其为曼哈顿范数，因为它测量了城市中的两点，沿着矩形的边行走的距离。
3. 更一般的，包含n个元素的矢量v的ℓk范数，定义成
   ℓ0只显示了这个矢量的基数（即，元素的个数），ℓ∞是矢量中最大的绝对值。 
```
$$
||V||_k=(|v_0|^k+|v_1|^k+...+|v_n|^k)^\frac{1}{k}
$$

```
4. 范数的指数越高，就越关注大的值而忽略小的值。这就是为什么RMSE比MAE对异常值更敏感。但是当异常值是指数分布的（类似正态曲线），RMSE就会表现很好。
```

### 核实假设**

最后，最好列出并核对迄今（你或其他人）作出的假设。这样可以尽早发现严重的问题。例如，你的系统输出的分区房价，会传入到下游的机器学习系统，我们假设这些价格确实会被当做分区房价使用。但是如果下游系统实际上将价格转化成了分类（例如，便宜、中等、昂贵），然后使用这些分类，而不是使用价格。这样的话，获得准确的价格就不那么重要了，你只需要得到合适的分类。问题相应地就变成了一个分类问题，而不是回归任务。你可不想在一个回归系统上工作了数月，最后才发现真相。

幸运的是，在与下游系统主管探讨之后，你很确信他们需要的就是实际的价格，而不是分类。很好！整装待发，可以开始写代码了。

### **获取数据**

### **快速查看数据结构**

```
count、mean、min和max几行的意思很明了。注意，空值被忽略了（所以，卧室总数是20433而不是20640）。std是标准差（揭示数值的分散度）。25%、50%、75%展示了对应的分位数：每个分位数指明小于这个值，且指定分组的百分比。例如，25%的分区的房屋年龄中位数小于18，而50%的小于29，75%的小于37。这些值通常称为25th分位数（或1st四分位数），中位数，75th分位数（3rd四分位数）。
另一种快速了解数据类型的方法是画出每个数值属性的柱状图。柱状图（的纵轴）展示了特定范围的实例的个数。你还可以一次给一个属性画图，或对完整数据集调用hist()方法，后者会画出每个数值属性的柱状图（见图2-8）。例如，你可以看到略微超过800个分区的median_house_value值差不多等于$500000。
```

### **创建测试集**

- 为什么要保留固定的测试集？

理论上，创建测试集很简单：只要随机挑选一些实例，一般是数据集的20%，放到一边 。

这个方法可行，但是并不完美：如果再次运行程序，就会产生一个不同的测试集！多次运行之后，你（或你的机器学习算法）就会得到整个数据集，这是需要避免的。

解决的办法之一是保存第一次运行得到的测试集，并在随后的过程加载。另一种方法是在调用np.random.permutation()之前，设置随机数生成器的种子（比如np.random.seed(42)），以产生总是相同的混合指数（shuffled indices）。

 但是如果获取更新后的数据集，这两个方法都会失效。 

- **采样偏差**

 目前为止，我们采用的都是纯随机的取样方法。当你的数据集很大时（尤其是和属性数相比），这通常可行；但如果数据集不大，就会有采样偏差的风险。 

```
当一个调查公司想要对1000个人进行调查，它们不是在电话亭里随机选1000个人出来。调查公司要保证这1000个人对人群整体有代表性。例如，美国人口的51.3%是女性，48.7%是男性。所以在美国，严谨的调查需要保证样本也是这个比例：513名女性，487名男性。这称作分层采样（stratified sampling）：将人群分成均匀的子分组，称为分层，从每个分层取出合适数量的实例，以保证测试集对总人数有代表性。如果调查公司采用纯随机采样，会有12%的概率导致采样偏差：女性人数少于49%，或多余54%。不管发生那种情况，调查结果都会严重偏差。
```

**假设专家告诉你，收入中位数是预测房价中位数非常重要的属性。**你可能想要保证测试集可以代表整体数据集中的多种收入分类。因为收入中位数是一个连续的数值属性，你首先需要创建一个收入分类属性。再仔细地看一下收入中位数的柱状图。

 数据集中的每个分层都要有足够的实例位于你的数据中，这点很重要。否则，对分层重要性的评估就会有偏差。这意味着，你不能有过多的分层，且每个分层都要足够大。 

### **数据探索和可视化、发现规律**

 另外，如果训练集非常大，你可能需要再采样一个探索集，保证操作方便快速。在我们的案例中，数据集很小，所以可以在全集上直接工作。创建一个副本，以免损伤训练集 。

- **数据可视化**
- **查找关联**

 你可以很容易地使用corr()方法计算出每对属性间的标准相关系数（也称作**皮尔逊相关系数**） 。

 相关系数的范围是-1到1。当接近1时，意味强正相关；例如，当收入中位数增加时，房价中位数也会增加。当相关系数接近-1时，意味强负相关 。

```
警告：相关系数只测量线性关系（如果x上升，y则上升或下降）。相关系数可能会完全忽略非线性关系（即，如果x接近0，则y值会变高）。在前面的计算结果中，底部的许多行的相关系数接近于0，尽管它们的轴并不独立：这些就是非线性关系的例子。另外，第二行的相关系数等于1或-1；这和斜率没有任何关系。例如，你的身高（单位是英寸）与身高（单位是英尺或纳米）的相关系数就是1。
```

 另一种检测属性间相关系数的方法是使用Pandas的scatter_matrix函数，它能画出每个数值属性对每个其它数值属性的图。 

- 属性组合试验

[注]    加工数据，查找关联性

希望前面的一节能教给你一些探索数据、发现规律的方法。你发现了一些数据的巧合，需要在给算法提供数据之前，将其去除。你还发现了一些属性间有趣的关联，特别是目标属性。你还注意到一些属性具有长尾分布，因此你可能要将其进行转换（例如，计算其log对数）。当然，不同项目的处理方法各不相同，但大体思路是相似的。

给算法准备数据之前，你需要做的最后一件事是尝试多种属性组合。例如，如果你不知道某个分区有多少户，该分区的总房间数就没什么用。你真正需要的是每户有几个房间。相似的，总卧室数也不重要：你可能需要将其与房间数进行比较。每户的人口数也是一个有趣的属性组合。让我们来创建这些新的属性：

这一步的数据探索不必非常完备，此处的目的是有一个正确的开始，快速发现规律，以得到一个合理的原型。但是这是一个交互过程：一旦你得到了一个原型，并运行起来，你就可以分析它的输出，进而发现更多的规律，然后再回到数据探索这步。

### **为机器学习算法准备数据**

- 切分特征和标签
- **数据清洗**

### **数据清洗**

### **数字**

大多机器学习算法不能处理特征丢失，因此先创建一些函数来处理特征丢失的问题。前面，你应该注意到了属性total_bedrooms有一些缺失值。有三个解决选项：

- 去掉对应的分区；？？？
- 去掉整个属性；
- 进行赋值（0、平均值、中位数等等）。

 用DataFrame的dropna()， drop()，和 fillna()方法，可以方便地实现

 如果选择选项3，你需要计算训练集的中位数，用中位数填充训练集的缺失值，不要忘记保存该中位数。后面用测试集评估系统时，需要替换测试集中的缺失值，也可以用来实时替换新数据中的缺失值。 

### **处理文本和分类属性**

- 大多数机器学习算法更喜欢和数字打交道，所以让我们把这些文本标签转换为数字。 
- 你可以查看映射表，编码器是通过属性classes_来学习的（“<1H OCEAN”被映射为0，“INLAND”被映射为1，等等）：

这种做法的问题是，ML算法会认为两个临近的值比两个疏远的值要更相似。显然这样不对（比如，分类0和4比0和1更相似）。要解决这个问题，一个常见的方法是给每个分类创建一个二元属性：当分类是“<1H OCEAN”，该属性为1（否则为0），当分类是“INLAND”，另一个属性等于1（否则为0），以此类推。

- 这称作独热编码(One-Hot Encoding)，因为只有一个属性会等于1（热），其余会是0（冷）。

### **特征缩放**

数据要做的最重要的转换之一是特征缩放。除了个别情况，当输入的数值属性量度不同时，机器学习算法的性能都不会好。

 有两种常见的方法可以让所有的属性有相同的量度：线性函数归一化（Min-Max scaling）和标准化（standardization）。

- 线性函数归一化

```
线性函数归一化（许多人称其为归一化（normalization））很简单：值被转变、重新缩放，直到范围变成0到1。我们通过减去最小值，然后再除以最大值与最小值的差值，来进行归一化。Scikit-Learn提供了一个转换量MinMaxScaler来实现这个功能。它有一个超参数feature_range，可以让你改变范围，如果不希望范围是0到1。
```

- 标准化

```
标准化就很不同：首先减去平均值（所以标准化值的平均值总是0），然后除以方差，使得到的分布具有单位方差。与归一化不同，标准化不会限定值到某个特定的范围，这对某些算法可能构成问题（比如，神经网络常需要输入值得范围是0到1）。但是，标准化受到异常值的影响很小。例如，假设一个分区的收入中位数是100。归一化会将其它范围是0到15的值变为0-0.15，但是标准化不会受什么影响。Scikit-Learn提供了一个转换量StandardScaler来进行标准化。
```

- 警告

```
警告：与所有的转换一样，缩放器只能向训练集拟合，而不是向完整的数据集（包括测试集）。只有这样，才能用缩放器转换训练集和测试集（和新数据）。
```

每个子pipeline都以一个选择转换量开始：通过选择对应的属性（数值或分类）、丢弃其它的，来转换数据，并将输出DataFrame转变成一个NumPy数组。Scikit-Learn没有工具来处理Pandas DataFrame，因此我们需要写一个简单的自定义转换量来做这项工作。

### **选择并训练模型(线性或非线性)**

### **交叉验证**

- K折交叉验证（K-fold cross-validation） 
- 可以验证过拟合和模型准确性

 它随机地将训练集分成十个不同的子集，成为“折”，然后训练评估决策树模型10次，每次选一个不用的折来做评估，用其它9个来做训练。结果是一个包含10个评分的数组

```
警告：Scikit-Learn交叉验证功能期望的是效用函数（越大越好）而不是成本函数（越低越好），因此得分函数实际上与MSE相反（即负值），这就是为什么前面的代码在计算平方根之前先计算-scores。
```

 注意到交叉验证不仅可以让你得到模型性能的评估(RMSE)，还能测量评估的准确性（即，它的标准差）。 

 如果只有一个验证集，就得不到这些信息。但是交叉验证的代价是训练了模型多次，不可能总是这样。 

### **过拟合**

 训练集的评分仍然比验证集的评分低很多，表示模型过拟合。

解决过拟合可以通过简化模型，给模型加限制（即，规整化），或用更多的训练数据。

在深入随机森林之前，你应该尝试下机器学习算法的其它类型模型（不同核心的支持向量机，神经网络，等等），不要在调节超参数上花费太多时间。目标是列出一个可能模型的列表（**两到五个**）。

```
提示：你要保存每个试验过的模型，以便后续可以再用。要确保有超参数和训练参数，以及交叉验证评分，和实际的预测值。这可以让你比较不同类型模型的评分，还可以比较误差种类。你可以用Python的模块pickle，非常方便地保存Scikit-Learn模型，或使用sklearn.externals.joblib，后者序列化大NumPy数组更有效率：
from sklearn.externals import joblib

joblib.dump(my_model, "my_model.pkl")
my_model_loaded = joblib.load("my_model.pkl")
```

### **模型微调**

- 网格搜索

微调的一种方法是手工调整超参数，直到找到一个好的超参数组合。这么做的话会非常冗长，你也可能没有时间探索多种组合。 

```
当你不能确定超参数该有什么值，一个简单的方法是尝试连续的10的次方（如果想要一个粒度更小的搜寻，可以用更小的数，就像在这个例子中对超参数n_estimators做的）。
```

 网格搜索，会训练每个模型五次（因为用的是五折交叉验证）。 

 如果GridSearchCV是以（默认值）refit=True开始运行的，则一旦用交叉验证找到了最佳的估计量，就会在整个训练集上重新训练。 

- 随机搜索( RandomizedSearchCV )

- 集成方法
- 分析最佳模型和它们的误差